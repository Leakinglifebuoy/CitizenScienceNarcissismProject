{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01be45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora, models\n",
    "import pprint\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections  \n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd3671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>project_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2183</td>\n",
       "      <td>Crows have been observed to gather and vocaliz...</td>\n",
       "      <td>Wild American crows gather around their dead t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2622</td>\n",
       "      <td>I will be searching caves across northeastern ...</td>\n",
       "      <td>Widespread Bat White-Nose Syndrome Fungus, Nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2108</td>\n",
       "      <td>On May 16, Dicty and HL60 cells will race for ...</td>\n",
       "      <td>When a healthy person suffers from a cut or a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>What makes some people react to the sight of t...</td>\n",
       "      <td>What do two men kissing and a bucket of maggot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3637</td>\n",
       "      <td>This study will use mobile technology to inves...</td>\n",
       "      <td>We've analyzed some data regarding eating beha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_id                                           abstract  \\\n",
       "0        2183  Crows have been observed to gather and vocaliz...   \n",
       "1        2622  I will be searching caves across northeastern ...   \n",
       "2        2108  On May 16, Dicty and HL60 cells will race for ...   \n",
       "3        1003  What makes some people react to the sight of t...   \n",
       "4        3637  This study will use mobile technology to inves...   \n",
       "\n",
       "                                 project_description  \n",
       "0  Wild American crows gather around their dead t...  \n",
       "1  Widespread Bat White-Nose Syndrome Fungus, Nor...  \n",
       "2  When a healthy person suffers from a cut or a ...  \n",
       "3  What do two men kissing and a bucket of maggot...  \n",
       "4  We've analyzed some data regarding eating beha...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('850-project_data.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9030b2",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30e8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将NLTK的词性标记映射到WordNet的词性标记 \n",
    "def get_wordnet_pos(treebank_tag): \n",
    "    if treebank_tag.startswith('J'): \n",
    "        return wordnet.ADJ \n",
    "    elif treebank_tag.startswith('V'): \n",
    "        return wordnet.VERB \n",
    "    elif treebank_tag.startswith('N'): \n",
    "        return wordnet.NOUN \n",
    "    elif treebank_tag.startswith('R'): \n",
    "        return wordnet.ADV \n",
    "    else: \n",
    "        return wordnet.NOUN\n",
    "# 定义函数进行处理 \n",
    "def get_cut_content(x): \n",
    "    x = re.sub(r\"\\d+\",' ',x)\n",
    "    x = re.sub(r\"[^\\w\\s]\",' ',x)\n",
    "    x = re.sub(r\"[^a-zA-Z ]+\",' ',x)\n",
    "    x = re.sub(\" +\", \" \", x)\n",
    "    x = x.lower()\n",
    "    words = nltk.word_tokenize(x) #分词\n",
    "    words = [word for word in words if word not in stopwords] \n",
    "    tagged_tokens = pos_tag(words) # 获取词性标记 \n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in tagged_tokens] # 词形还原 \n",
    "    words=lemmatized_tokens\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c383421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#停用词\n",
    "hit_stopwords = [line.rstrip() for line in open('stopwords.txt', encoding='utf-8')] #英文停用词\n",
    "mystopwords = [line.rstrip() for line in open('mystopwords.txt', encoding='utf-8')] #自定义停用词\n",
    "stopwords = hit_stopwords+mystopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5102121",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['project_description'].astype(str) #lda建模目标\n",
    "#进行预处理\n",
    "text_cut = text.map(lambda x:get_cut_content(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c345553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除预处理后空白的\n",
    "text_cut = text_cut.loc[text_cut.map(lambda x:len(x)>0)]\n",
    "text = text.loc[text_cut.index]\n",
    "data = data.loc[text_cut.index]\n",
    "text.index = range(text.shape[0])\n",
    "text_cut.index = range(text_cut.shape[0])\n",
    "data.index = range(data.shape[0])\n",
    "data['text_cut'] = text_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f45eae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [wild, american, crow, gather, dead, learn, da...\n",
       "1      [widespread, bat, white, nose, syndrome, fungu...\n",
       "2      [healthy, person, suffers, cut, burn, immune, ...\n",
       "3      [kiss, bucket, maggot, common, heterosexual, i...\n",
       "4      [analyze, data, eat, behavors, mother, project...\n",
       "                             ...                        \n",
       "845    [joy, start, family, pregnant, healthy, baby, ...\n",
       "846    [hawai, coral, reef, fish, specie, saddle, wra...\n",
       "847    [albatross, scour, mile, ocean, forage, food, ...\n",
       "848    [fresco, paint, medium, trace, ancient, civili...\n",
       "849    [zika, virus, zikv, transmit, aedes, mosquito,...\n",
       "Name: text_cut, Length: 850, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_cut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a7e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==词频统计\n",
    "all_words = list(itertools.chain(*text_cut)) #全部的单词\n",
    "word_counts = collections.Counter(all_words)  #做词频统计\n",
    "word_counts_top = word_counts.most_common()# 获取前N最高频的词####-------------重要的\n",
    "pd.DataFrame(word_counts_top,columns=['word','count']).to_excel('词频统计结果.xlsx',index=0) #保存词频统计结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621332f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
